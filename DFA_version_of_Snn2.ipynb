{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaNalla/SNN-with-IFA/blob/main/DFA_version_of_Snn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbNYPZ5_wvtf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import core libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# for evaluation purposes, importing scikit.metric\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new cell 2 for LIF neuron\n",
        "class LIFNeuron:\n",
        "    \"\"\"\n",
        "    Leaky Integrate-and-Fire neuron implementation.\n",
        "\n",
        "    This class demonstrates the LIF dynamics before incorporating into layers.\n",
        "    Paper reference: Appendix A, Equations A.1-A.4\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tau=20.0, dt=0.25, threshold=0.2, t_ref=1.0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tau: Membrane time constant (ms) - controls leak rate\n",
        "            dt: Time step (ms) - discretization step\n",
        "            threshold: Spike threshold (h_th)\n",
        "            t_ref: Refractory period (ms) - time after spike when neuron can't fire\n",
        "\n",
        "        Paper settings (Section B):\n",
        "            - tau = 20ms\n",
        "            - dt = 0.25ms\n",
        "            - threshold = 0.4\n",
        "            - t_ref = 1ms\n",
        "        \"\"\"\n",
        "        self.tau = tau # the leak rate\n",
        "        self.dt = dt # time step\n",
        "        self.threshold = threshold # voltage threshold\n",
        "        self.t_ref = t_ref # time after the neuron cant fire\n",
        "\n",
        "        # Calculate leak factor (1 - dt/tau)\n",
        "        self.alpha = 1.0 - (dt / tau)\n",
        "        # Calculate input scaling (dt/tau)\n",
        "        self.beta = dt / tau\n",
        "\n",
        "        # State variables\n",
        "        self.v = 0.0  # Membrane potential\n",
        "        self.ref_count = 0  # Refractory counter (in time steps)\n",
        "\n",
        "    def step(self, input_current):\n",
        "        \"\"\"\n",
        "        Single time step of LIF dynamics.\n",
        "\n",
        "        Args:\n",
        "            input_current: Weighted sum of inputs at this time step\n",
        "\n",
        "        Returns:\n",
        "            spike: 1 if neuron fired, 0 otherwise\n",
        "        \"\"\"\n",
        "        spike = 0\n",
        "\n",
        "        # Check if in refractory period\n",
        "        if self.ref_count > 0:\n",
        "            self.ref_count -= 1\n",
        "            self.v = 0.0  # Keep voltage at 0 during refractory\n",
        "            return spike\n",
        "\n",
        "        # Update membrane potential (Equation A.2)\n",
        "        self.v = self.alpha * self.v + self.beta * input_current\n",
        "\n",
        "        # Check for spike (Equation A.3)\n",
        "        if self.v >= self.threshold:\n",
        "            spike = 1\n",
        "            self.v = 0.0  # Reset (Equation A.4)\n",
        "            # Enter refractory period\n",
        "            self.ref_count = int(self.t_ref / self.dt)\n",
        "            # we want to wait 1 ms, so we divide the amount of time by the time steps\n",
        "            # in this particular instance of 1 ms, we would have to wait 4 time steps\n",
        "            # before this neuron can fire again\n",
        "\n",
        "        return spike"
      ],
      "metadata": {
        "id": "RAoqcq7koF9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_weight_stats(num_neurons, v_mean=8.0, v_second_moment=164.0, alpha=0.066):\n",
        "    \"\"\"\n",
        "    Compute weight initialization statistics.\n",
        "    Paper reference: Appendix C, Equations A.7 and A.8\n",
        "\n",
        "    Args:\n",
        "        num_neurons: Number of neurons in layer (N)\n",
        "        v_mean: Mean input value (v̄)\n",
        "        v_second_moment: Second moment of input (v̄̄)\n",
        "        alpha: Constant (0.066)\n",
        "\n",
        "    Returns:\n",
        "        w_mean: Mean weight value (W̄_n)\n",
        "        w_std: Standard deviation (σ_{W_n})\n",
        "    \"\"\"\n",
        "    # Equation A.7: W̄_n = (v̄ - 0.8) / (α · N · v̄)\n",
        "    w_mean = (v_mean - 0.8) / (alpha * num_neurons * v_mean)\n",
        "\n",
        "    # Equation A.8: W̄̄_n for computing standard deviation\n",
        "    numerator = (v_second_moment +\n",
        "                 alpha**2 * (num_neurons - num_neurons**2) * w_mean**2 * v_mean**2 -\n",
        "                 1.6 * alpha * num_neurons * v_mean * w_mean -\n",
        "                 0.64)\n",
        "    denominator = alpha**2 * num_neurons * v_second_moment\n",
        "\n",
        "    w_second_moment = numerator / denominator\n",
        "\n",
        "    # Calculate standard deviation from second moment\n",
        "    w_std = np.sqrt(w_second_moment - w_mean**2)\n",
        "\n",
        "    return w_mean, w_std\n",
        "\n",
        "\n",
        "def initialize_feedback_matrix(output_shape, input_shape,\n",
        "                                w_mean_next, w_std_next,\n",
        "                                gamma=0.1,\n",
        "                                num_downstream_layers=1):\n",
        "    \"\"\"\n",
        "    Initialize fixed random feedback matrix B.\n",
        "    Paper reference: Appendix B, Equation A.5\n",
        "\n",
        "    Args:\n",
        "        output_shape: Number of neurons this layer projects to\n",
        "        input_shape: Number of neurons in this layer\n",
        "        w_mean_next: Mean of weights in next layer\n",
        "        w_std_next: Std of weights in next layer\n",
        "        gamma: Scale factor (0.0338 in paper) but using other values\n",
        "        num_downstream_layers: Number of layers between this and output (D)\n",
        "\n",
        "    Returns:\n",
        "        B: Fixed random feedback matrix [input_shape, output_shape]\n",
        "    \"\"\"\n",
        "    # Generate random matrix with paper's specific distribution\n",
        "    # B_n = γ · [W̄_{n+1} + 2√3 · σ_{W_{n+1}} · (rand - 0.5)]\n",
        "\n",
        "    rand_values = np.random.uniform(0, 1, size=(input_shape, output_shape))\n",
        "\n",
        "    # Apply paper's formula\n",
        "    B = w_mean_next + 2 * np.sqrt(3) * w_std_next * (rand_values - 0.5)\n",
        "\n",
        "    # Apply scaling factor\n",
        "    B = gamma * B\n",
        "\n",
        "    # Note: Paper mentions product over downstream layers (∏)\n",
        "    # For simplicity with 2-layer network, we use single multiplication\n",
        "    # For deeper networks, you'd multiply B matrices from all downstream layers\n",
        "\n",
        "    return B.astype(np.float32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "feedback_init"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DFA_LIFLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    LIF layer that outputs spikes over time.\n",
        "    Has fixed random feedback matrix B for DFA training.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, units, output_size,\n",
        "                 tau=20.0, dt=0.25, threshold=0.2, t_ref=1.0,\n",
        "                 use_dfa=True, gamma=0.0338):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.units = units\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.tau = tau\n",
        "        self.dt = dt\n",
        "        self.threshold = threshold\n",
        "        self.t_ref = t_ref\n",
        "        self.use_dfa = use_dfa\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # Trainable weights (like add_weight trainable=True)\n",
        "        self.w = nn.Parameter(torch.empty(in_features, units))\n",
        "        self.b = nn.Parameter(torch.zeros(units))\n",
        "        nn.init.constant_(self.b, 0.2)\n",
        "\n",
        "        # Init roughly like Keras Glorot-ish (you can match your stats init if you want)\n",
        "        nn.init.xavier_uniform_(self.w)\n",
        "\n",
        "        # Refractory steps\n",
        "        self.ref_steps = int(round(self.t_ref / self.dt))\n",
        "\n",
        "        # Fixed random feedback matrix B (like add_weight trainable=False)\n",
        "        if use_dfa:\n",
        "            B_init = torch.randn(units, output_size) * self.gamma\n",
        "            self.register_buffer(\"B\", B_init)  # NOT a Parameter -> not trainable\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs: [batch, time, in_features]\n",
        "        returns spikes: [batch, time, units]\n",
        "        \"\"\"\n",
        "        batch_size, time_steps, _ = inputs.shape\n",
        "\n",
        "        v = torch.zeros(batch_size, self.units, device=inputs.device)\n",
        "        ref_count = torch.zeros(batch_size, self.units, device=inputs.device)\n",
        "\n",
        "        spikes_out = []\n",
        "\n",
        "        alpha = 1.0 - (self.dt / self.tau)\n",
        "        beta  = self.dt / self.tau\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            x_t = inputs[:, t, :]\n",
        "\n",
        "            I_t = (x_t @ self.w) + self.b\n",
        "            v = alpha * v + beta * I_t\n",
        "\n",
        "            # refractory\n",
        "            v = torch.where(ref_count > 0, torch.zeros_like(v), v)\n",
        "\n",
        "            # spike + reset\n",
        "            spikes = (v >= self.threshold).float()\n",
        "            v = v * (1.0 - spikes)\n",
        "\n",
        "            # update refractory counter\n",
        "            ref_count = ref_count - 1.0\n",
        "            ref_count = torch.where(spikes > 0, torch.ones_like(ref_count) * self.ref_steps, ref_count)\n",
        "            ref_count = torch.clamp(ref_count, min=0.0)\n",
        "\n",
        "            spikes_out.append(spikes)\n",
        "\n",
        "        return torch.stack(spikes_out, dim=1)\n",
        "    # def forward(self, inputs):\n",
        "    #     \"\"\"\n",
        "    #     inputs: [batch, time, in_features]\n",
        "    #     returns spikes: [batch, time, units]\n",
        "    #     \"\"\"\n",
        "    #     batch_size, time_steps, _ = inputs.shape\n",
        "\n",
        "    #     v = torch.zeros(batch_size, self.units, device=inputs.device)\n",
        "    #     ref_count = torch.zeros(batch_size, self.units, device=inputs.device)\n",
        "\n",
        "    #     spikes_out = []\n",
        "\n",
        "    #     alpha = 1.0 - (self.dt / self.tau)\n",
        "    #     beta  = self.dt / self.tau\n",
        "\n",
        "    #     I_t = (x_t @ self.w) + self.b\n",
        "    #     v = alpha * v + beta * I_t\n",
        "\n",
        "    #     for t in range(time_steps):\n",
        "    #         x_t = inputs[:, t, :]  # [batch, in_features]\n",
        "\n",
        "    #         # current to voltage update\n",
        "    #         dv = (x_t @ self.w) + self.b\n",
        "    #         v = alpha * v + (1 - alpha) * dv\n",
        "\n",
        "    #         # handle refractory: if ref_count>0, clamp or stop integration\n",
        "    #         v = torch.where(ref_count > 0, torch.zeros_like(v), v)\n",
        "\n",
        "    #         spikes = (v >= self.threshold).float()\n",
        "    #         v = v * (1.0 - spikes)\n",
        "\n",
        "    #         # update refractory counter\n",
        "    #         ref_count = ref_count - 1.0\n",
        "    #         ref_count = torch.where(spikes > 0, torch.ones_like(ref_count) * self.ref_steps, ref_count)\n",
        "    #         ref_count = torch.clamp(ref_count, min=0.0)\n",
        "\n",
        "    #         spikes_out.append(spikes)\n",
        "\n",
        "    #     return torch.stack(spikes_out, dim=1)  # [batch, time, units]"
      ],
      "metadata": {
        "id": "3wdjozUNxfMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# math function (PyTorch version)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def surrogate_gradient_exact(a, h_th=0.2, t_ref=1.0, tau=20.0): # original threshold was 0,4\n",
        "    \"\"\"\n",
        "    Exact surrogate gradient from paper (Appendix D, Equation A.9).\n",
        "    PyTorch version.\n",
        "    \"\"\"\n",
        "    eps = 1e-8\n",
        "\n",
        "    # Compute ratio a / (a - h_th)\n",
        "    ratio = a / (a - h_th + eps)\n",
        "\n",
        "    # Numerator: h_th * t_ref * tau / [a * (a - h_th)]\n",
        "    numerator = h_th * t_ref * tau / (a * (a - h_th) + eps)\n",
        "\n",
        "    # Denominator: [t_ref + tau * log(ratio)]^2\n",
        "    log_term = torch.log(ratio + eps)\n",
        "    denominator = (t_ref + tau * log_term) ** 2 + eps\n",
        "\n",
        "    grad = numerator / denominator\n",
        "\n",
        "    # Only non-zero where a > threshold\n",
        "    grad = torch.where(a > h_th, grad, torch.zeros_like(grad))\n",
        "\n",
        "    return grad\n",
        "\n",
        "\n",
        "def surrogate_gradient_fast_sigmoid(a, threshold=0.2, alpha=5): # original threshold was 0,4\n",
        "    \"\"\"\n",
        "    Fast sigmoid surrogate gradient (PyTorch version).\n",
        "    \"\"\"\n",
        "    shifted = a - threshold\n",
        "    grad = 1.0 / (1.0 + torch.abs(alpha * shifted)) ** 2\n",
        "    return grad\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Visualize both surrogate gradients\n",
        "# ----------------------------\n",
        "a_values = np.linspace(-2, 2, 1000)\n",
        "threshold = 0.4\n",
        "\n",
        "# Convert to torch tensors\n",
        "a_torch = torch.tensor(a_values, dtype=torch.float32)\n",
        "\n",
        "# Compute gradients\n",
        "grad_exact = surrogate_gradient_exact(\n",
        "    a_torch,\n",
        "    h_th=threshold\n",
        ").detach().cpu().numpy()\n",
        "\n",
        "grad_sigmoid = surrogate_gradient_fast_sigmoid(\n",
        "    a_torch,\n",
        "    threshold=threshold\n",
        ").detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "6HQjJ0LhMW6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: PyTorch model (matches your Keras topology)\n",
        "class DFASNN(nn.Module):\n",
        "    def __init__(self, time_steps, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.time_steps = time_steps\n",
        "\n",
        "        # Hidden layer with DFA feedback matrix B\n",
        "        self.hidden_layer = DFA_LIFLayer(\n",
        "            in_features=input_size,\n",
        "            units=hidden_size,\n",
        "            output_size=output_size,\n",
        "            tau=20.0,\n",
        "            dt=0.25,\n",
        "            threshold=0.2, # play with this (original was 0.4)\n",
        "            t_ref=1.0,\n",
        "            use_dfa=True,\n",
        "            gamma=0.0338\n",
        "        )\n",
        "\n",
        "        # Output layer (no B matrix)\n",
        "        self.output_layer = DFA_LIFLayer(\n",
        "            in_features=hidden_size,\n",
        "            units=output_size,\n",
        "            output_size=output_size,\n",
        "            tau=20.0,\n",
        "            dt=0.25,\n",
        "            threshold=0.2, # maybe play with this (original was 0.4)\n",
        "            t_ref=1.0,\n",
        "            use_dfa=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x_time):\n",
        "        \"\"\"\n",
        "        x_time: [batch, time, 784]  (matches your Keras input exactly)\n",
        "        returns:\n",
        "          h_spikes: [batch, time, hidden]\n",
        "          y_spikes: [batch, time, 10]\n",
        "        \"\"\"\n",
        "        h_spikes = self.hidden_layer(x_time)\n",
        "        y_spikes = self.output_layer(h_spikes)\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        #   print(\"mean hidden spike:\", h_spikes.mean().item(),\n",
        "        #   \"mean output spike:\", y_spikes.mean().item())\n",
        "        return h_spikes, y_spikes"
      ],
      "metadata": {
        "id": "qlY7nl0nAokQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: PyTorch DFA trainer (manual DFA updates, no autograd needed)\n",
        "class DFATrainerTorch:\n",
        "    def __init__(self, model, learning_rate=0.1, use_exact_gradient=True):\n",
        "        self.model = model\n",
        "        self.lr = learning_rate\n",
        "        self.use_exact_gradient = use_exact_gradient\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_spike_rate(spikes):\n",
        "        # match your TF version: sum over time\n",
        "        return spikes.sum(dim=1)  # [batch, units]\n",
        "\n",
        "    def train_step(self, x_time, y_onehot):\n",
        "        \"\"\"\n",
        "        x_time: [b,t,784]\n",
        "        y_onehot: [b,10]\n",
        "        returns: (loss_float, acc_float)\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        x_time = x_time.to(device)\n",
        "        y_onehot = y_onehot.to(device)\n",
        "\n",
        "        # Forward\n",
        "        h_spikes, y_spikes = self.model(x_time)          # [b,t,hidden], [b,t,10]\n",
        "        out_rates = self.compute_spike_rate(y_spikes)    # [b,10]\n",
        "        out_probs = F.softmax(out_rates, dim=1)          # [b,10]\n",
        "\n",
        "        eps = 1e-9\n",
        "        loss = -(y_onehot * torch.log(out_probs + eps)).sum(dim=1).mean()\n",
        "\n",
        "        # Global error\n",
        "        e_global = out_probs - y_onehot                  # [b,10]\n",
        "        e_time = e_global.unsqueeze(1).repeat(1, y_spikes.size(1), 1)  # [b,t,10]\n",
        "\n",
        "        bsz, T, _ = y_spikes.shape\n",
        "        denom = float(bsz * T)\n",
        "\n",
        "        # Manual updates (no autograd)\n",
        "        with torch.no_grad():\n",
        "            # ----- Output layer update -----\n",
        "            out_layer = self.model.output_layer\n",
        "            out_input = h_spikes  # output layer input is hidden spikes [b,t,hidden]\n",
        "\n",
        "            a_out = (out_input @ out_layer.w) + out_layer.b  # [b,t,10]\n",
        "\n",
        "            if self.use_exact_gradient:\n",
        "                fprime_out = surrogate_gradient_exact(a_out, h_th=out_layer.threshold,\n",
        "                                                      t_ref=out_layer.t_ref, tau=out_layer.tau)\n",
        "            else:\n",
        "                fprime_out = surrogate_gradient_fast_sigmoid(a_out, threshold=out_layer.threshold, alpha=10.0)\n",
        "\n",
        "            e_out = e_time * fprime_out  # [b,t,10]\n",
        "\n",
        "            grad_w_out = torch.einsum(\"bti,btj->ij\", out_input, e_out) / denom\n",
        "            grad_b_out = e_out.sum(dim=(0, 1)) / denom\n",
        "\n",
        "            out_layer.w -= self.lr * grad_w_out\n",
        "            out_layer.b -= self.lr * grad_b_out\n",
        "\n",
        "            # ----- Hidden layer DFA update -----\n",
        "            hid_layer = self.model.hidden_layer\n",
        "            # Project error through fixed B: [b,t,10] x [hidden,10] -> [b,t,hidden]\n",
        "            e_proj = torch.einsum(\"bto,ho->bth\", e_time, hid_layer.B)\n",
        "\n",
        "            a_hid = (x_time @ hid_layer.w) + hid_layer.b  # [b,t,hidden]\n",
        "\n",
        "            if self.use_exact_gradient:\n",
        "                fprime_hid = surrogate_gradient_exact(a_hid, h_th=hid_layer.threshold,\n",
        "                                                      t_ref=hid_layer.t_ref, tau=hid_layer.tau)\n",
        "            else:\n",
        "                fprime_hid = surrogate_gradient_fast_sigmoid(a_hid, threshold=hid_layer.threshold, alpha=10.0)\n",
        "\n",
        "            e_hid = e_proj * fprime_hid  # [b,t,hidden]\n",
        "\n",
        "            grad_w_hid = torch.einsum(\"bti,btj->ij\", x_time, e_hid) / denom\n",
        "            grad_b_hid = e_hid.sum(dim=(0, 1)) / denom\n",
        "\n",
        "            hid_layer.w -= self.lr * grad_w_hid\n",
        "            hid_layer.b -= self.lr * grad_b_hid\n",
        "\n",
        "        # Accuracy\n",
        "        preds = torch.argmax(out_probs, dim=1)\n",
        "        true = torch.argmax(y_onehot, dim=1)\n",
        "        acc = (preds == true).float().mean().item()\n",
        "\n",
        "        return loss.item(), acc\n",
        "\n",
        "    def fit(self, x_time_all, y_onehot_all, epochs=20, batch_size=128, verbose=1):\n",
        "      history = {\"loss\": [], \"accuracy\": []}\n",
        "      n = x_time_all.shape[0]\n",
        "\n",
        "      for ep in range(epochs):\n",
        "          perm = torch.randperm(n)\n",
        "          ep_loss = 0.0\n",
        "          ep_acc = 0.0\n",
        "          nb = 0\n",
        "\n",
        "          for i in range(0, n, batch_size):\n",
        "              idx = perm[i:i+batch_size]\n",
        "              xb_time = x_time_all[idx].to(device)\n",
        "              yb_onehot = y_onehot_all[idx].to(device)\n",
        "\n",
        "              loss, acc = self.train_step(xb_time, yb_onehot)\n",
        "\n",
        "              ep_loss += loss\n",
        "              ep_acc += acc\n",
        "              nb += 1\n",
        "\n",
        "          history[\"loss\"].append(ep_loss / nb)\n",
        "          history[\"accuracy\"].append(ep_acc / nb)\n",
        "\n",
        "          if verbose:\n",
        "              print(f\"Epoch {ep+1}/{epochs} - loss: {history['loss'][-1]:.4f} - acc: {history['accuracy'][-1]:.4f}\")\n",
        "\n",
        "      return history"
      ],
      "metadata": {
        "id": "VZku5B2bApSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# PyTorch version of that ONE cell (data prep + build + train + plot)\n",
        "# Assumes you already defined: DFA_LIFLayer, DFASNN, DFATrainerTorch (from earlier port steps)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# Load MNIST data (PyTorch)\n",
        "# ----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                  # -> float32 in [0,1], shape [1,28,28]\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # -> [784]\n",
        "])\n",
        "\n",
        "train_ds_full = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds_full  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Convert to tensors (to mirror your \"x_train, y_train\" arrays)\n",
        "# Note: this iterates through the dataset once; fine for MNIST.\n",
        "x_train = torch.stack([train_ds_full[i][0] for i in range(len(train_ds_full))]).float()  # [60000,784]\n",
        "y_train_int = torch.tensor([train_ds_full[i][1] for i in range(len(train_ds_full))], dtype=torch.long)  # [60000]\n",
        "\n",
        "x_test  = torch.stack([test_ds_full[i][0] for i in range(len(test_ds_full))]).float()    # [10000,784]\n",
        "y_test_int  = torch.tensor([test_ds_full[i][1] for i in range(len(test_ds_full))], dtype=torch.long)   # [10000]\n",
        "\n",
        "# One-hot encode labels (to match your Keras cell exactly)\n",
        "y_train = F.one_hot(y_train_int, num_classes=10).float()  # [60000,10]\n",
        "y_test  = F.one_hot(y_test_int, num_classes=10).float()   # [10000,10]\n",
        "\n",
        "print(f\"Training samples: {len(x_train)}\")\n",
        "print(f\"Test samples: {len(x_test)}\")\n",
        "print(f\"Input shape: {x_train.shape[1]}\")\n",
        "print(f\"Output classes: {y_train.shape[1]}\")\n",
        "\n",
        "TIME_STEPS = 25   # Reduced from 100 for faster training\n",
        "HIDDEN_SIZE = 1000\n",
        "OUTPUT_SIZE = 10\n",
        "INPUT_SIZE = 784\n",
        "\n",
        "# INCREASED: Use larger dataset\n",
        "TRAIN_SAMPLES = 30000\n",
        "x_train_small = x_train[:TRAIN_SAMPLES]          # [30000,784]\n",
        "y_train_small = y_train[:TRAIN_SAMPLES]          # [30000,10]\n",
        "y_train_small_int = y_train_int[:TRAIN_SAMPLES]  # [30000]\n",
        "\n",
        "# Expand to time dimension (paper uses \"direct mapping\")\n",
        "# Just repeat the input for each time step\n",
        "# (Matches your np.tile logic, but in torch)\n",
        "x_train_spikes = x_train_small.unsqueeze(1).repeat(1, TIME_STEPS, 1)  # [30000,25,784]\n",
        "\n",
        "print(f\"\\nInput shape with time: {tuple(x_train_spikes.shape)}\")\n",
        "print(f\"  [batch={x_train_spikes.shape[0]}, \"\n",
        "      f\"time={x_train_spikes.shape[1]}, \"\n",
        "      f\"features={x_train_spikes.shape[2]}]\")\n",
        "\n",
        "# ----------------------------\n",
        "# Build DFA-SNN model (PyTorch)\n",
        "# ----------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILDING DFA-SNN MODEL (PyTorch)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Safety checks (so you get a clear error if earlier port cells aren't run yet)\n",
        "missing = []\n",
        "for name in [\"DFA_LIFLayer\", \"DFASNN\", \"DFATrainerTorch\"]:\n",
        "    if name not in globals():\n",
        "        missing.append(name)\n",
        "if missing:\n",
        "    raise NameError(\n",
        "        \"You haven't defined these yet in earlier cells: \"\n",
        "        + \", \".join(missing)\n",
        "        + \"\\nRun the cells where you ported the layer/model/trainer first.\"\n",
        "    )\n",
        "\n",
        "model = DFASNN(\n",
        "    time_steps=TIME_STEPS,\n",
        "    input_size=INPUT_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    output_size=OUTPUT_SIZE\n",
        ").to(device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# ----------------------------\n",
        "# Create DFA trainer (PyTorch)\n",
        "# ----------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INITIALIZING DFA TRAINER (PyTorch)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer = DFATrainerTorch(\n",
        "    model=model,\n",
        "    learning_rate=0.1  # matches your cell\n",
        ")\n",
        "\n",
        "# Mirror your \"dfa layers found\" printout as closely as possible\n",
        "dfa_layers = []\n",
        "if hasattr(model, \"hidden_layer\"):\n",
        "    dfa_layers.append(model.hidden_layer)\n",
        "if hasattr(model, \"output_layer\"):\n",
        "    dfa_layers.append(model.output_layer)\n",
        "\n",
        "print(f\"\\nDFA layers found: {len(dfa_layers)}\")\n",
        "for layer in dfa_layers:\n",
        "    B_shape = tuple(layer.B.shape) if hasattr(layer, \"B\") else None\n",
        "    print(f\"  {layer.__class__.__name__}:\")\n",
        "    print(f\"    Units: {layer.units}\")\n",
        "    print(f\"    B shape: {B_shape}\")\n",
        "    print(f\"    Learning rate: {trainer.lr:.6f}\")\n",
        "\n",
        "\n",
        "\n",
        "# We already built x_train_spikes as a full tensor [30000,25,784]\n",
        "# To keep this as a single-cell replica, we’ll train on it directly in batches.\n",
        "batch_size = 128\n",
        "epochs = 1\n",
        "\n",
        "history = trainer.fit(x_train_spikes, y_train_small, epochs=50, batch_size=128, verbose=1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epochs = np.arange(1, len(history[\"accuracy\"]) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, history[\"accuracy\"], marker='o', linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Epochs (DFA-SNN)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.xticks(epochs if len(epochs) <= 20 else None)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eBfUTSjSHxk6",
        "outputId": "b32c49a8-416b-499c-bb16-b8cb2e6d4f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 60000\n",
            "Test samples: 10000\n",
            "Input shape: 784\n",
            "Output classes: 10\n",
            "\n",
            "Input shape with time: (30000, 25, 784)\n",
            "  [batch=30000, time=25, features=784]\n",
            "\n",
            "============================================================\n",
            "BUILDING DFA-SNN MODEL (PyTorch)\n",
            "============================================================\n",
            "DFASNN(\n",
            "  (hidden_layer): DFA_LIFLayer()\n",
            "  (output_layer): DFA_LIFLayer()\n",
            ")\n",
            "\n",
            "============================================================\n",
            "INITIALIZING DFA TRAINER (PyTorch)\n",
            "============================================================\n",
            "\n",
            "DFA layers found: 2\n",
            "  DFA_LIFLayer:\n",
            "    Units: 1000\n",
            "    B shape: (1000, 10)\n",
            "    Learning rate: 0.100000\n",
            "  DFA_LIFLayer:\n",
            "    Units: 10\n",
            "    B shape: None\n",
            "    Learning rate: 0.100000\n",
            "Epoch 1/50 - loss: 2.3026 - acc: 0.0985\n",
            "Epoch 2/50 - loss: 2.3026 - acc: 0.0988\n",
            "Epoch 3/50 - loss: 2.3005 - acc: 0.1003\n",
            "Epoch 4/50 - loss: 2.1783 - acc: 0.2000\n",
            "Epoch 5/50 - loss: 1.9523 - acc: 0.4247\n",
            "Epoch 6/50 - loss: 1.7864 - acc: 0.5470\n",
            "Epoch 7/50 - loss: 1.7319 - acc: 0.5316\n",
            "Epoch 8/50 - loss: 1.6551 - acc: 0.5255\n",
            "Epoch 9/50 - loss: 1.5803 - acc: 0.5482\n",
            "Epoch 10/50 - loss: 1.5046 - acc: 0.5731\n",
            "Epoch 11/50 - loss: 1.4413 - acc: 0.6031\n",
            "Epoch 12/50 - loss: 1.3852 - acc: 0.6346\n",
            "Epoch 13/50 - loss: 1.3428 - acc: 0.6542\n",
            "Epoch 14/50 - loss: 1.3079 - acc: 0.6715\n",
            "Epoch 15/50 - loss: 1.2779 - acc: 0.6856\n",
            "Epoch 16/50 - loss: 1.2494 - acc: 0.6995\n",
            "Epoch 17/50 - loss: 1.2214 - acc: 0.7104\n",
            "Epoch 18/50 - loss: 1.1955 - acc: 0.7219\n",
            "Epoch 19/50 - loss: 1.1701 - acc: 0.7307\n",
            "Epoch 20/50 - loss: 1.1470 - acc: 0.7374\n",
            "Epoch 21/50 - loss: 1.1234 - acc: 0.7462\n",
            "Epoch 22/50 - loss: 1.1029 - acc: 0.7523\n",
            "Epoch 23/50 - loss: 1.0845 - acc: 0.7569\n",
            "Epoch 24/50 - loss: 1.0660 - acc: 0.7625\n",
            "Epoch 25/50 - loss: 1.0489 - acc: 0.7666\n",
            "Epoch 26/50 - loss: 1.0328 - acc: 0.7702\n",
            "Epoch 27/50 - loss: 1.0178 - acc: 0.7734\n",
            "Epoch 28/50 - loss: 1.0044 - acc: 0.7762\n",
            "Epoch 29/50 - loss: 0.9906 - acc: 0.7812\n",
            "Epoch 30/50 - loss: 0.9777 - acc: 0.7829\n",
            "Epoch 31/50 - loss: 0.9673 - acc: 0.7862\n",
            "Epoch 32/50 - loss: 0.9562 - acc: 0.7894\n",
            "Epoch 33/50 - loss: 0.9458 - acc: 0.7924\n",
            "Epoch 34/50 - loss: 0.9364 - acc: 0.7937\n",
            "Epoch 35/50 - loss: 0.9262 - acc: 0.7965\n",
            "Epoch 36/50 - loss: 0.9176 - acc: 0.7985\n",
            "Epoch 37/50 - loss: 0.9096 - acc: 0.8001\n",
            "Epoch 38/50 - loss: 0.9020 - acc: 0.8016\n",
            "Epoch 39/50 - loss: 0.8950 - acc: 0.8039\n",
            "Epoch 40/50 - loss: 0.8874 - acc: 0.8050\n",
            "Epoch 41/50 - loss: 0.8799 - acc: 0.8073\n",
            "Epoch 42/50 - loss: 0.8728 - acc: 0.8093\n",
            "Epoch 43/50 - loss: 0.8655 - acc: 0.8103\n",
            "Epoch 44/50 - loss: 0.8586 - acc: 0.8129\n",
            "Epoch 45/50 - loss: 0.8523 - acc: 0.8141\n",
            "Epoch 46/50 - loss: 0.8473 - acc: 0.8141\n",
            "Epoch 47/50 - loss: 0.8414 - acc: 0.8160\n",
            "Epoch 48/50 - loss: 0.8363 - acc: 0.8166\n",
            "Epoch 49/50 - loss: 0.8313 - acc: 0.8183\n",
            "Epoch 50/50 - loss: 0.8260 - acc: 0.8193\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}