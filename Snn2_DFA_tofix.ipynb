{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbNYPZ5_wvtf"
      },
      "outputs": [],
      "source": [
        "# Import core libraries\n",
        "import tensorflow as tf  # Main deep learning framework\n",
        "from tensorflow import keras  # High-level neural network API\n",
        "import numpy as np  # Numerical computing library\n",
        "import matplotlib.pyplot as plt  # Plotting library for visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FBnk4NZ_pswa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Define LIF Layer with Surrogate Gradient (FIXED)\n",
        "@tf.custom_gradient\n",
        "def spike_function(v, threshold):\n",
        "    \"\"\"\n",
        "    Spike function with surrogate gradient.\n",
        "    Forward pass: Hard threshold (Heaviside step function)\n",
        "    Backward pass: Smooth gradient (fast sigmoid surrogate)\n",
        "    \"\"\"\n",
        "    # Forward pass: Generate actual spikes (1 if v > threshold, else 0)\n",
        "    spikes = tf.cast(tf.greater(v, threshold), tf.float32)\n",
        "\n",
        "    def grad(dy):\n",
        "        \"\"\"\n",
        "        Backward pass: Use fast sigmoid surrogate gradient.\n",
        "        Derivative of fast sigmoid: 1 / (1 + |alpha * (v - threshold)|)^2\n",
        "        \"\"\"\n",
        "        alpha = 10.0  # Steepness parameter for surrogate gradient\n",
        "        # Compute distance from threshold\n",
        "        v_shifted = v - threshold\n",
        "        # Fast sigmoid surrogate gradient\n",
        "        surrogate_grad = 1.0 / (1.0 + tf.abs(alpha * v_shifted)) ** 2\n",
        "        # Scale by incoming gradient\n",
        "        dv = dy * surrogate_grad\n",
        "        # Return gradients for v and threshold (threshold is constant, so None)\n",
        "        return dv, None\n",
        "\n",
        "    return spikes, grad  # Return spikes and gradient function\n",
        "\n",
        "\n",
        "class LIFLayer(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Leaky Integrate-and-Fire neuron layer with surrogate gradient training.\n",
        "    Uses smooth gradients during backprop for trainability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, output_units=None, tau=20.0, threshold=1.0, use_dfa=True, is_output_layer=False, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the LIF layer with specified parameters.\n",
        "\n",
        "        Args:\n",
        "            units: Number of neurons in this layer\n",
        "            tau: Membrane time constant (controls leak rate)\n",
        "            threshold: Voltage threshold for spike generation\n",
        "\n",
        "            output units: number of output neurons\n",
        "            use_dfa = whether to use dfa or normal backprop\n",
        "            is_output_layer = whether this is the output layer\n",
        "        \"\"\"\n",
        "        super(LIFLayer, self).__init__(**kwargs)\n",
        "        self.units = units  # Store number of neurons\n",
        "        self.output_units = output_units  # Store number of output neurons\n",
        "        self.tau = tau  # Store time constant for membrane potential decay\n",
        "        self.threshold = threshold  # Store spike threshold value\n",
        "        self.use_dfa = use_dfa  # Store whether to use dfa or normal backprop\n",
        "        self.is_output_layer = is_output_layer  # Store whether this is the output layer\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Build layer weights - called automatically when layer is first used.\n",
        "        Creates the weight matrix connecting inputs to neurons.\n",
        "        \"\"\"\n",
        "        # Create weight matrix with Xavier initialization for stable gradients\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),  # Shape: [input_dim, num_neurons]\n",
        "            initializer='glorot_uniform',  # Xavier uniform initialization\n",
        "            trainable=True,  # Weights will be updated during training\n",
        "            name='weights'  # Name for debugging\n",
        "        )\n",
        "        # Create bias vector, one bias per neuron\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,),  # Shape: [num_neurons]\n",
        "            initializer='zeros',  # Initialize biases to zero\n",
        "            trainable=True,  # Biases will be updated during training\n",
        "            name='bias'  # Name for debugging\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Compute the output shape of the layer.\n",
        "        Output has same batch and time dimensions, but neuron dimension changes.\n",
        "        \"\"\"\n",
        "        # Return shape: [batch, time_steps, units]\n",
        "        return (input_shape[0], input_shape[1], self.units)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Forward pass through the LIF layer with surrogate gradient.\n",
        "        Simulates spiking neuron dynamics over time.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor of shape [batch, time_steps, input_dim]\n",
        "\n",
        "        Returns:\n",
        "            Spike tensor of shape [batch, time_steps, units]\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]  # Get batch size from input\n",
        "        time_steps = tf.shape(inputs)[1]  # Get number of time steps (dynamic)\n",
        "\n",
        "        # Initialize membrane potential to zero for all neurons\n",
        "        v = tf.zeros((batch_size, self.units))  # Shape: [batch, units]\n",
        "\n",
        "        # Use TensorArray to store spikes (works with symbolic tensors)\n",
        "        spikes_array = tf.TensorArray(\n",
        "            dtype=tf.float32,  # Data type for spikes\n",
        "            size=time_steps,  # Size equals number of time steps\n",
        "            dynamic_size=False  # Fixed size array\n",
        "        )\n",
        "\n",
        "        # Define loop body function for time step iteration\n",
        "        def time_step(t, v, spikes_array):\n",
        "            \"\"\"\n",
        "            Process one time step: compute current, update voltage, generate spikes.\n",
        "            Uses surrogate gradient for spike generation.\n",
        "            \"\"\"\n",
        "            # Extract input at current time step\n",
        "            x_t = inputs[:, t, :]  # Shape: [batch, input_dim]\n",
        "\n",
        "            # Compute input current: weighted sum + bias\n",
        "            i_in = tf.matmul(x_t, self.w) + self.b  # Shape: [batch, units]\n",
        "\n",
        "            # Update membrane potential with leak and input\n",
        "            # dv/dt = -v/tau + i_in approximated as: v = v*(1-1/tau) + i_in\n",
        "            v = v * (1.0 - 1.0/self.tau) + i_in  # Leaky integration\n",
        "\n",
        "            # Generate spikes using surrogate gradient function\n",
        "            # Forward: hard threshold, Backward: smooth gradient\n",
        "            spike = spike_function(v, self.threshold)\n",
        "\n",
        "            # Reset membrane potential for neurons that spiked\n",
        "            v = v * (1.0 - spike)  # Multiply by (1-spike) to reset spiking neurons to 0\n",
        "\n",
        "            # Write spikes to array at current time index\n",
        "            spikes_array = spikes_array.write(t, spike)\n",
        "\n",
        "            # Return updated values for next iteration\n",
        "            return t + 1, v, spikes_array\n",
        "\n",
        "        # Run loop over all time steps using tf.while_loop (TensorFlow's loop)\n",
        "        _, _, spikes_array = tf.while_loop(\n",
        "            cond=lambda t, *_: t < time_steps,  # Continue while t < time_steps\n",
        "            body=time_step,  # Function to execute each iteration\n",
        "            loop_vars=[0, v, spikes_array]  # Initial values: [t=0, v, spikes_array]\n",
        "        )\n",
        "\n",
        "        # Convert TensorArray to regular tensor and transpose\n",
        "        output = spikes_array.stack()  # Shape: [time_steps, batch, units]\n",
        "        output = tf.transpose(output, [1, 0, 2])  # Transpose to [batch, time_steps, units]\n",
        "\n",
        "        return output  # Return spike trains"
      ],
      "metadata": {
        "id": "JuIhwtW0xAyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Build 2-Layer SNN Model\n",
        "def create_snn_model(input_dim, hidden_units, output_units, time_steps):\n",
        "    \"\"\"\n",
        "    Create a simple 2-layer dense SNN.\n",
        "\n",
        "    Args:\n",
        "        input_dim: Dimension of input features\n",
        "        hidden_units: Number of neurons in hidden layer\n",
        "        output_units: Number of output neurons (classes)\n",
        "        time_steps: Number of time steps for simulation\n",
        "\n",
        "    Returns:\n",
        "        Keras model representing the SNN\n",
        "    \"\"\"\n",
        "    # Define input layer: [batch, time_steps, input_dim]\n",
        "    inputs = keras.Input(shape=(time_steps, input_dim), name='input')\n",
        "\n",
        "    # First LIF layer (hidden layer) - processes temporal input\n",
        "    hidden = LIFLayer(\n",
        "        units=hidden_units,  # Number of hidden neurons\n",
        "        tau=20.0,  # Membrane time constant\n",
        "        threshold=1.0,  # Spike threshold\n",
        "        name='hidden_layer'  # Layer name\n",
        "    )(inputs)  # Apply to input\n",
        "\n",
        "    # Second LIF layer (output layer) - produces classification spikes\n",
        "    outputs = LIFLayer(\n",
        "        units=output_units,  # Number of output classes\n",
        "        tau=20.0,  # Membrane time constant\n",
        "        threshold=1.0,  # Spike threshold\n",
        "        name='output_layer'  # Layer name\n",
        "    )(hidden)  # Apply to hidden layer output\n",
        "\n",
        "    # Create the model by connecting inputs to outputs\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name='2layer_snn')\n",
        "\n",
        "    return model  # Return the complete model"
      ],
      "metadata": {
        "id": "BMJqY4LkxE-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Create Rate Coding Function\n",
        "def rate_encode(data, time_steps, max_rate=1.0):\n",
        "    \"\"\"\n",
        "    Convert static data to spike trains using rate coding.\n",
        "    Higher input values produce more spikes over time.\n",
        "\n",
        "    Args:\n",
        "        data: Input data of shape [batch, features]\n",
        "        time_steps: Number of time steps to encode\n",
        "        max_rate: Maximum firing rate\n",
        "\n",
        "    Returns:\n",
        "        Spike trains of shape [batch, time_steps, features]\n",
        "    \"\"\"\n",
        "    # Normalize input data to [0, 1] range\n",
        "    data = np.clip(data, 0, 1)  # Ensure values are between 0 and 1\n",
        "    #clip just sets the max as 1 and the min as 0\n",
        "\n",
        "    # Generate random numbers for probabilistic spike generation\n",
        "    rand = np.random.rand(data.shape[0], time_steps, data.shape[1])\n",
        "\n",
        "    # Create spikes where random value < input value * max_rate\n",
        "    # Higher input values = higher probability of spikes\n",
        "    spikes = (rand < data[:, np.newaxis, :] * max_rate).astype(np.float32)\n",
        "\n",
        "    return spikes  # Return encoded spike trains"
      ],
      "metadata": {
        "id": "i7Of7nJJxzIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Load and Prepare MNIST Dataset\n",
        "# Load MNIST handwritten digit dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Flatten images from 28x28 to 784-dimensional vectors\n",
        "x_train = x_train.reshape(-1, 784).astype('float32')  # Shape: [60000, 784]\n",
        "x_test = x_test.reshape(-1, 784).astype('float32')  # Shape: [10000, 784]\n",
        "\n",
        "# Normalize pixel values to [0, 1] range\n",
        "x_train = x_train / 255.0  # Divide by max pixel value\n",
        "x_test = x_test / 255.0  # Divide by max pixel value\n",
        "\n",
        "#manual normalization here\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)  # Shape: [60000, 10]\n",
        "y_test = keras.utils.to_categorical(y_test, 10)  # Shape: [10000, 10]\n",
        "\n",
        "# Use smaller subset for faster training\n",
        "num_samples = 1000  # Number of training samples\n",
        "x_train = x_train[:num_samples]  # Take first 1000 samples\n",
        "y_train = y_train[:num_samples]  # Take corresponding labels\n",
        "\n",
        "print(f\"Training data shape: {x_train.shape}\")  # Print shape for verification\n",
        "print(f\"Training labels shape: {y_train.shape}\")  # Print shape for verification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yks19QP5x1He",
        "outputId": "f2bf259b-601e-4c57-cc38-0fbb480708db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (1000, 784)\n",
            "Training labels shape: (1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Encode Data as Spike Trains\n",
        "time_steps = 20  # Number of time steps for simulation, for exmaple seconds\n",
        "\n",
        "# Convert training data to spike trains using rate coding\n",
        "x_train_spikes = rate_encode(x_train, time_steps, max_rate=0.8)\n",
        "print(f\"Spike train shape: {x_train_spikes.shape}\")  # Should be [1000, 20, 784]\n",
        "\n",
        "#rate coding is basically getting input from the average spikes over a period of time\n",
        "\n",
        "# Convert test data to spike trains\n",
        "x_test_spikes = rate_encode(x_test, time_steps, max_rate=0.8)\n",
        "print(f\"Test spike train shape: {x_test_spikes.shape}\")  # Should be [10000, 20, 784]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDUJg5jZx4f9",
        "outputId": "1ab8cb04-12f9-4119-cd53-c58635dd449e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spike train shape: (1000, 20, 784)\n",
            "Test spike train shape: (10000, 20, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Create and Compile Model with Surrogate Gradient Training\n",
        "# Create SNN with specified architecture\n",
        "model = create_snn_model(\n",
        "    input_dim=784,  # MNIST flattened image size\n",
        "    hidden_units=128,  # Number of hidden layer neurons\n",
        "    output_units=10,  # Number of output classes (digits 0-9)\n",
        "    time_steps=time_steps  # Number of simulation time steps\n",
        ")\n",
        "\n",
        "# Print model architecture summary\n",
        "model.summary()  # Shows layer types, output shapes, and parameters\n",
        "\n",
        "# Define custom loss function for spike-based classification\n",
        "def spike_categorical_crossentropy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Loss function that compares spike counts to target labels.\n",
        "    Sum spikes over time and compute crossentropy.\n",
        "    \"\"\"\n",
        "    # Sum spikes across time dimension to get firing rates\n",
        "    spike_counts = tf.reduce_sum(y_pred, axis=1)  # Shape: [batch, output_units]\n",
        "\n",
        "    # Apply softmax to convert spike counts to probabilities\n",
        "    probs = tf.nn.softmax(spike_counts)  # Normalize to probability distribution\n",
        "\n",
        "    # Compute categorical crossentropy loss\n",
        "    loss = keras.losses.categorical_crossentropy(y_true, probs)\n",
        "\n",
        "    return loss  # Return scalar loss value\n",
        "\n",
        "# Define custom accuracy metric for spike-based classification\n",
        "def spike_categorical_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Accuracy metric that sums spikes over time before comparing to labels.\n",
        "    \"\"\"\n",
        "    # Sum spikes across time dimension to get total spike counts\n",
        "    spike_counts = tf.reduce_sum(y_pred, axis=1)  # Shape: [batch, output_units]\n",
        "\n",
        "    # Get predicted class (neuron with most spikes)\n",
        "    y_pred_class = tf.argmax(spike_counts, axis=-1)  # Shape: [batch]\n",
        "\n",
        "    # Get true class from one-hot labels\n",
        "    y_true_class = tf.argmax(y_true, axis=-1)  # Shape: [batch]\n",
        "\n",
        "    # Compare predictions to true labels\n",
        "    matches = tf.equal(y_pred_class, y_true_class)  # Boolean tensor\n",
        "\n",
        "    # Convert to float (1.0 for match, 0.0 for mismatch)\n",
        "    accuracy = tf.cast(matches, tf.float32)\n",
        "\n",
        "    return accuracy  # Return accuracy values\n",
        "\n",
        "# Compile model with optimizer, loss, and surrogate gradient training\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer\n",
        "    loss=spike_categorical_crossentropy,  # Spike-based loss\n",
        "    metrics=[spike_categorical_accuracy]  # Spike-based accuracy\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Model compiled with surrogate gradient training!\")\n",
        "print(\"Forward pass: Hard spike threshold\")\n",
        "print(\"Backward pass: Smooth fast sigmoid gradient (alpha=10)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "U-JXFianx9-H",
        "outputId": "bfaf7c7a-7308-4739-d3f5-ea662a244f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"2layer_snn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"2layer_snn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m784\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (\u001b[38;5;33mLIFLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mLIFLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LIFLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LIFLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Model compiled with surrogate gradient training!\n",
            "Forward pass: Hard spike threshold\n",
            "Backward pass: Smooth fast sigmoid gradient (alpha=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Train the SNN\n",
        "# Train model on spike-encoded MNIST data\n",
        "history = model.fit(\n",
        "    x_train_spikes,  # Input: spike trains\n",
        "    y_train,  # Target: one-hot labels\n",
        "    batch_size=32,  # Number of samples per gradient update\n",
        "    epochs=10,  # Number of full passes through dataset\n",
        "    validation_split=0.2,  # Use 20% of data for validation\n",
        "    verbose=1  # Print progress bar\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEwGdUPvyBd_",
        "outputId": "76e23a02-f42f-47b9-f63b-4fbe9f912f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 2.5630 - spike_categorical_accuracy: 0.2765 - val_loss: 1.1714 - val_spike_categorical_accuracy: 0.6600\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.9031 - spike_categorical_accuracy: 0.7070 - val_loss: 0.9908 - val_spike_categorical_accuracy: 0.7250\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.5991 - spike_categorical_accuracy: 0.7900 - val_loss: 0.7237 - val_spike_categorical_accuracy: 0.7900\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.3048 - spike_categorical_accuracy: 0.9124 - val_loss: 0.7231 - val_spike_categorical_accuracy: 0.8100\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1242 - spike_categorical_accuracy: 0.9673 - val_loss: 0.6850 - val_spike_categorical_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.1308 - spike_categorical_accuracy: 0.9631 - val_loss: 0.6529 - val_spike_categorical_accuracy: 0.8200\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.1106 - spike_categorical_accuracy: 0.9712 - val_loss: 0.6223 - val_spike_categorical_accuracy: 0.8350\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0384 - spike_categorical_accuracy: 0.9940 - val_loss: 0.6492 - val_spike_categorical_accuracy: 0.8300\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0519 - spike_categorical_accuracy: 0.9861 - val_loss: 0.6361 - val_spike_categorical_accuracy: 0.8350\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0561 - spike_categorical_accuracy: 0.9833 - val_loss: 0.6326 - val_spike_categorical_accuracy: 0.8300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dS7s1zngzpZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}